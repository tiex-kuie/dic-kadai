{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのimport\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価指標\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'keras'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tixt1\\Desktop\\機械学習特別研修\\dive-into-code-kadai-8-1.ipynb Cell 3\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tixt1/Desktop/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E7%89%B9%E5%88%A5%E7%A0%94%E4%BF%AE/dive-into-code-kadai-8-1.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# データセットをダウンロードするコード\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tixt1/Desktop/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E7%89%B9%E5%88%A5%E7%A0%94%E4%BF%AE/dive-into-code-kadai-8-1.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mkeras\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m mnist\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tixt1/Desktop/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E7%89%B9%E5%88%A5%E7%A0%94%E4%BF%AE/dive-into-code-kadai-8-1.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m (X_train, y_train), (X_test, y_test) \u001b[39m=\u001b[39m mnist\u001b[39m.\u001b[39mload_data()\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'keras'"
     ]
    }
   ],
   "source": [
    "# データセットをダウンロードするコード\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "# print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "# X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray')\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 型変換、正規化\n",
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニング データと検証データに分割\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2)\n",
    "print(X_train.shape)\n",
    "print(X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 正しいラベル値のワンホット エンコーディング\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_val_one_hot = enc.transform(y_val[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチ処理クラス\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=None):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ミニバッチ処理\n",
    "get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "print(len(get_mini_batch)) # 2400\n",
    "print(get_mini_batch[5]) # 5番目のミニバッチが取得できる\n",
    "\n",
    "for mini_X_train, mini_y_train in get_mini_batch:\n",
    "    # このfor文内でミニバッチが使える\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ニューラルネットワークスクラッチ\n",
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな3層ニューラルネットワーク分類器\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, n_epoch=50, n_features=784, n_nodes1=400, n_nodes2=200, \n",
    "                 n_output=10, sigma=0.01, n_batch=20, \n",
    "                 activate_function_key='tanh', lr = 0.01, verbose = False):\n",
    "        \n",
    "        self.n_epoch = n_epoch\n",
    "        self.n_features = n_features\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.sigma = sigma\n",
    "        self.n_batch = n_batch\n",
    "        self.activate_function_key = activate_function_key\n",
    "        self.lr = lr\n",
    "        self.verbose = verbose\n",
    "        \n",
    "    def initial_weight(self):\n",
    "        self.W1 = self.sigma * np.random.randn(self.n_features, self.n_nodes1)\n",
    "        self.b1 = np.zeros(self.n_nodes1)\n",
    "        self.W2 = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
    "        self.b2 = np.zeros(self.n_nodes2)\n",
    "        self.W3 = self.sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
    "        self.b3 = np.zeros(self.n_output)\n",
    "        \n",
    "    def activation_function(self,X):\n",
    "        if self.activate_function_key == 'sigmoid':\n",
    "            return 1/(1+np.exp(-X))\n",
    "        \n",
    "        elif self.activate_function_key == 'tanh':\n",
    "            return np.tanh(X)\n",
    "    \n",
    "    def softmax(self,X):\n",
    "        \n",
    "        return np.exp(X-np.max(X))/np.sum(np.exp(X-np.max(X)),axis=1,keepdims=True)\n",
    "    \n",
    "    def loss_function(self,y,yt):\n",
    "        delta = 1e-7\n",
    "        return -np.mean(yt*np.log(y+delta))\n",
    "    \n",
    "    def gradient_descent(self,X,y,yt):\n",
    "        \n",
    "            # 3rd layer\n",
    "            delta_a3 = (y-yt)/self.n_batch\n",
    "            delta_b3 = np.sum(delta_a3,axis=0)\n",
    "            delta_W3 = np.dot(self.z2.T,delta_a3)\n",
    "            delta_z2 = np.dot(delta_a3,self.W3.T)\n",
    "        \n",
    "            self.W3 -= self.lr*delta_W3\n",
    "            self.b3 -= self.lr*delta_b3\n",
    "        \n",
    "            # 2nd layer\n",
    "            if self.activate_function_key == 'sigmoid':\n",
    "                delta_a2 = delta_z2*(1-self.activation_function(self.z2))*self.activation_function(self.z2)\n",
    "            \n",
    "            elif self.activate_function_key == 'tanh':\n",
    "                delta_a2 = delta_z2*(1-np.tanh(self.z2)**2)\n",
    "            \n",
    "            delta_b2 = np.sum(delta_a2,axis=0)\n",
    "            delta_W2 = np.dot(self.z1.T,delta_a2)\n",
    "            delta_z1 = np.dot(delta_a2,self.W2.T)\n",
    "        \n",
    "            self.W2 -= self.lr*delta_W2\n",
    "            self.b2 -= self.lr*delta_b2\n",
    "        \n",
    "            # 1st layer\n",
    "            if self.activate_function_key == 'sigmoid':\n",
    "                delta_a1 = delta_z1*(1-self.activation_function(self.z1))*self.activation_function(self.z1)\n",
    "            \n",
    "            elif self.activate_function_key == 'tanh':\n",
    "                delta_a1 = delta_z1*(1-np.tanh(self.z1)**2)\n",
    "                \n",
    "            delta_b1 = np.sum(delta_a1,axis=0)\n",
    "            delta_W1 = np.dot(X.T,delta_a1)\n",
    "        \n",
    "            self.W1 -= self.lr*delta_W1\n",
    "            self.b1 -= self.lr*delta_b1\n",
    "                \n",
    "    def fit(self, X, y, X_val=False, y_val=False):\n",
    "        \"\"\"\n",
    "        Train a neural network classifier.。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of the following form, shape (n_samples, n_features)\n",
    "            Features of training data\n",
    "        y : ndarray of the following form, shape (n_samples, )\n",
    "            Correct answer value of training data\n",
    "        X_val : ndarray of the following form, shape (n_samples, n_features)\n",
    "            Features of validation data\n",
    "        y_val : ndarray of the following form, shape (n_samples, )\n",
    "            Correct value of validation data\n",
    "        \"\"\"\n",
    "        # 重みの初期化\n",
    "        self.initial_weight()\n",
    "        \n",
    "        # 各エポックの loss_function を記録するリスト\n",
    "        self.log_loss = []\n",
    "        self.log_loss_val = []\n",
    "        \n",
    "        # エポックごとのトレーニングデータの推定値を評価する: 精度\n",
    "        self.log_acc = []\n",
    "        self.log_acc_val = []\n",
    "        \n",
    "        for epoch in range(self.n_epoch):\n",
    "            # ミニバッチ処理\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.n_batch)\n",
    "            \n",
    "            self.loss = 0\n",
    "            self.true_y = np.array([])\n",
    "            self.pred_y = np.array([])\n",
    "            \n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "            \n",
    "                # 1st layer\n",
    "                self.z1 = self.activation_function(np.dot(mini_X_train,self.W1) + self.b1)\n",
    "            \n",
    "                # 2nd layer\n",
    "                self.z2 = self.activation_function(np.dot(self.z1,self.W2) + self.b2)\n",
    "            \n",
    "                # 3rd layer (ソフトマックス関数)\n",
    "                yhat = self.softmax(np.dot(self.z2,self.W3) + self.b3)\n",
    "                \n",
    "                # バックプロパゲーション（確率的勾配降下法）\n",
    "                self.gradient_descent(mini_X_train,yhat,mini_y_train)\n",
    "                \n",
    "                # ミニバッチ データの正しい値と推定値を記録する\n",
    "                self.true_y = np.concatenate([self.true_y,np.argmax(mini_y_train,axis=1)])\n",
    "                self.pred_y = np.concatenate([self.pred_y,np.argmax(yhat,axis=1)])\n",
    "                \n",
    "                # 損失関数\n",
    "                self.loss += self.loss_function(yhat,mini_y_train)\n",
    "            \n",
    "            # 各エポックの損失関数を記録する\n",
    "            self.log_loss.append(self.loss/len(get_mini_batch))\n",
    "            \n",
    "            # 精度\n",
    "            acc = accuracy_score(self.true_y, self.pred_y)\n",
    "            self.log_acc.append(acc)\n",
    "            \n",
    "            # Val データが入力されたら計算する\n",
    "            if (type(X_val) != bool):\n",
    "                # 1st layer\n",
    "                self.z1_val = self.activation_function(np.dot(X_val,self.W1) + self.b1)\n",
    "            \n",
    "                # 2nd layer\n",
    "                self.z2_val = self.activation_function(np.dot(self.z1_val,self.W2) + self.b2)\n",
    "            \n",
    "                # 3rd layer (ソフトマックス関数)\n",
    "                yhat_val = self.softmax(np.dot(self.z2_val,self.W3) + self.b3)\n",
    "                \n",
    "                # 損失関数\n",
    "                self.loss_val = self.loss_function(yhat_val,y_val)\n",
    "                self.log_loss_val.append(self.loss_val)\n",
    "                \n",
    "                # 精度\n",
    "                \n",
    "                acc_val = accuracy_score(np.argmax(y_val,axis=1), np.argmax(yhat_val,axis=1))\n",
    "                self.log_acc_val.append(acc_val)\n",
    "            \n",
    "            #verbose を true に設定すると、学習過程などを出力する\n",
    "            if self.verbose:\n",
    "                print('epoch:{:>3} loss:{:>8,.3f} acc:{:>5,.3f}'.format(epoch,self.loss/self.n_batch,acc))\n",
    "            \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Estimate using a neural network classifier.。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : ndarray of the following form, shape (n_samples, n_features)\n",
    "            Sample\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            ndarray of the following form, shape (n_samples, 1)\n",
    "            Estimation results\n",
    "        \"\"\"\n",
    "        # 1st layer\n",
    "        self.pred_z1 = self.activation_function(np.dot(X,self.W1) + self.b1)\n",
    "            \n",
    "        # 2nd layer\n",
    "        self.pred_z2 = self.activation_function(np.dot(self.pred_z1,self.W2) + self.b2)\n",
    "        \n",
    "        return np.argmax(np.dot(self.pred_z2,self.W3) + self.b3, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題1:重みの初期値を決めるコードの作成\n",
    "\n",
    "# 重みの初期値\n",
    "n_features = 784\n",
    "n_nodes1 = 400\n",
    "n_nodes2 = 200\n",
    "n_output =10\n",
    "\n",
    "# ガウス分布の標準偏差\n",
    "sigma = 0.01 \n",
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "print('W1',W1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W1 = sigma * np.random.randn(n_features, n_nodes1)\n",
    "b1 = sigma * np.random.randn(n_nodes1)\n",
    "W2 = sigma * np.random.randn(n_nodes1, n_nodes2)\n",
    "b2 = sigma * np.random.randn(n_nodes2)\n",
    "W3 = sigma * np.random.randn(n_nodes2, n_output)\n",
    "b3 = sigma * np.random.randn(n_output)\n",
    "\n",
    "print('W1',W1.shape)\n",
    "print('W2',W2.shape)\n",
    "print('W3',W3.shape)\n",
    "print('b1',b1.shape)\n",
    "print('b2',b2.shape)\n",
    "print('b3',b3.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題2:フォワードプロバケーションの実装\n",
    "\n",
    "X = X_train[0:20]\n",
    "\n",
    "# 第1層の線形結合\n",
    "z1 = np.dot(X,W1)# + b1\n",
    "print('z1.shape:',z1.shape)\n",
    "print(z1)\n",
    "\n",
    "# 第1層の活性化関数\n",
    "sig1 = 1/(1+np.exp(-z1))\n",
    "print('sig1.shape:',sig1.shape)\n",
    "print(sig1)\n",
    "\n",
    "# 2層目の線形結合\n",
    "z2 = np.dot(sig1,W2) + b2\n",
    "print('z2.shape:',z2.shape)\n",
    "print(z2)\n",
    "\n",
    "# 2層目の活性化関数\n",
    "sig2 = 1/(1+np.exp(-z2))\n",
    "print('sig2.shape:',sig2.shape)\n",
    "print(sig2)\n",
    "\n",
    "# 第3層の線形結合\n",
    "z3 = np.dot(sig2,W3) + b3\n",
    "print('z3.shape:',z3.shape)\n",
    "print(z3)\n",
    "\n",
    "# 第3層の活性化関数（ソフトマックス関数）\n",
    "sfmax = np.zeros([len(X),10])\n",
    "for i in range(20):\n",
    "    sfmax[i] = np.exp(z3[i])/np.sum(np.exp(z3[i]),axis=0)\n",
    "print('sfmax.shape:',sfmax.shape)\n",
    "print(sfmax)\n",
    "print(np.sum(sfmax))\n",
    "\n",
    "# for文を使わずに計算\n",
    "softmax = np.exp(z3).T/np.sum(np.exp(z3),axis=1)\n",
    "print('softmax.shape:',softmax.shape)\n",
    "print(softmax.T)\n",
    "print(np.sum(softmax))\n",
    "\n",
    "# for文を使わずに計算\n",
    "softmax = np.exp(z3)/np.sum(np.exp(z3),axis=1,keepdims=True)\n",
    "print('softmax.shape:',softmax.shape)\n",
    "print(softmax)\n",
    "print(np.sum(softmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパボリックタンジェント\n",
    "np.tanh(z1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ハイパボリックタンジェント(検証)\n",
    "(np.exp(z1)-np.exp(-z1))/(np.exp(z1)+np.exp(-z1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題3:交差エントロピーの実装\n",
    "\n",
    "y = y_train_one_hot[0:20]\n",
    "loss = -y*np.log(sfmax)/len(y)\n",
    "print('shape:\\n',loss.shape)\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題4:バックプロバケーションの実装\n",
    "\n",
    "# 3rd layer\n",
    "delta_a3 = sfmax-y\n",
    "delta_b3 = np.sum(delta_a3,axis=0)\n",
    "delta_W3 = np.dot(z2.T,delta_a3)\n",
    "delta_z2 = np.dot(delta_a3,W3.T)\n",
    "\n",
    "print(delta_a3.shape)\n",
    "print(delta_b3.shape)\n",
    "print(delta_W3.shape)\n",
    "print(delta_z2.shape)\n",
    "\n",
    "# 2nd layer\n",
    "delta_a2 = delta_z2*(1-np.tanh(z2)**2)\n",
    "delta_b2 = np.sum(delta_a2,axis=0)\n",
    "delta_W2 = np.dot(z1.T,delta_a2)\n",
    "delta_z1 = np.dot(delta_a2,W2.T)\n",
    "\n",
    "# 1st layer\n",
    "delta_a1 = delta_z1*(1-np.tanh(z1)**2)\n",
    "delta_b1 = np.sum(delta_a1,axis=0)\n",
    "delta_W1 = np.dot(X.T,delta_a1)\n",
    "\n",
    "print(delta_a1.shape)\n",
    "print(delta_b1.shape)\n",
    "print(delta_W1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題5:推定\n",
    "\n",
    "clf = ScratchSimpleNeuralNetrowkClassifier(n_epoch=30, n_features=784,\n",
    "                                           n_nodes1=400, n_nodes2=200, n_output=10,\n",
    "                                           sigma=0.01, n_batch=100,\n",
    "                                           activate_function_key='tanh',\n",
    "                                           lr = 0.01, verbose = True)\n",
    "\n",
    "clf.fit(X_train,y_train_one_hot,X_val,y_val_one_hot)\n",
    "y_pred = clf.predict(X_val)\n",
    "\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題6:学習と推定\n",
    "\n",
    "accuracy = accuracy_score(y_val, y_pred)\n",
    "#precision = precision_score(y_val, y_pred)\n",
    "#recall = recall_score(y_val, y_pred)\n",
    "#f1 = f1_score(y_val, y_pred)\n",
    "\n",
    "print('accuracy:{:.3f}'.format(accuracy))\n",
    "#print('precision',precision)\n",
    "#print('recall',recall)\n",
    "#print('f1',f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題7:学習曲線のプロット\n",
    "\n",
    "# 各エポックの損失関数を可視化する\n",
    "fig = plt.subplots(figsize=(12,8))\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "plt.plot(clf.log_loss,'rs--')\n",
    "plt.plot(clf.log_loss_val,'bo--');\n",
    "\n",
    "# エポックごとの正答率の可視化\n",
    "fig = plt.subplots(figsize=(12,8))\n",
    "plt.rcParams[\"font.size\"] = 20\n",
    "\n",
    "plt.plot(clf.log_acc,'rs--')\n",
    "plt.plot(clf.log_acc_val,'bo--');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題8:(アドバンス課題)誤分類の確認\n",
    "\n",
    "\"\"\"\n",
    "語分類結果を並べて表示する。画像の上の表示は「推定結果/正解」である。\n",
    "\n",
    "Parameters:\n",
    "----------\n",
    "y_pred : 推定値のndarray (n_samples,)\n",
    "y_val : 検証データの正解ラベル(n_samples,)\n",
    "X_val : 検証データの特徴量（n_samples, n_features)\n",
    "\"\"\"\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "num = 5 # いくつ表示するか\n",
    "print('Estimation result / correct answer')\n",
    "\n",
    "true_false = y_pred==y_val\n",
    "false_list = np.where(true_false==False)[0].astype(np.int)\n",
    "if false_list.shape[0] < num:\n",
    "    num = false_list.shape[0]\n",
    "fig = plt.figure(figsize=(6, 6))\n",
    "fig.subplots_adjust(left=0, right=0.8,  bottom=0, top=0.8, hspace=1, wspace=0.5)\n",
    "for i in range(num):\n",
    "    ax = fig.add_subplot(6, 6, i + 1, xticks=[], yticks=[])\n",
    "    ax.set_title(\"{} / {}\".format(y_pred[false_list[i]],y_val[false_list[i]]))\n",
    "    ax.imshow(X_val.reshape(-1,28,28)[false_list[i]], cmap='gray')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bde1ea82a499da0f3bee45254b930e19212c5f0c991811db65179495d8206895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
