{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ライブラリのインポート\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\tixt1\\anaconda3\\lib\\site-packages\\sklearn\\experimental\\enable_hist_gradient_boosting.py:16: UserWarning: Since version 1.0, it is not needed to import enable_hist_gradient_boosting anymore. HistGradientBoostingClassifier and HistGradientBoostingRegressor are now stable and can be normally imported from sklearn.ensemble.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 学習用モデルのインポート\n",
    "from sklearn.linear_model import LinearRegression, Ridge, Lasso, ElasticNet, SGDRegressor\n",
    "from sklearn.linear_model import PassiveAggressiveRegressor, ARDRegression, RidgeCV\n",
    "from sklearn.linear_model import TheilSenRegressor, RANSACRegressor, HuberRegressor\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.svm import SVR, LinearSVR\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.experimental import enable_hist_gradient_boosting\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor, ExtraTreesRegressor, HistGradientBoostingRegressor\n",
    "from sklearn.ensemble import BaggingRegressor, GradientBoostingRegressor, VotingRegressor, StackingRegressor\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.cross_decomposition import PLSRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評価指標\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'google.colab'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\tixt1\\Desktop\\機械学習特別研修\\dive-into-code-kadai-7-1.ipynb Cell 4\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/tixt1/Desktop/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E7%89%B9%E5%88%A5%E7%A0%94%E4%BF%AE/dive-into-code-kadai-7-1.ipynb#Y244sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mgoogle\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcolab\u001b[39;00m \u001b[39mimport\u001b[39;00m drive\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tixt1/Desktop/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E7%89%B9%E5%88%A5%E7%A0%94%E4%BF%AE/dive-into-code-kadai-7-1.ipynb#Y244sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m drive\u001b[39m.\u001b[39mmount(\u001b[39m'\u001b[39m\u001b[39m/content/drive\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/tixt1/Desktop/%E6%A9%9F%E6%A2%B0%E5%AD%A6%E7%BF%92%E7%89%B9%E5%88%A5%E7%A0%94%E4%BF%AE/dive-into-code-kadai-7-1.ipynb#Y244sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m get_ipython()\u001b[39m.\u001b[39mrun_line_magic(\u001b[39m'\u001b[39m\u001b[39mcd\u001b[39m\u001b[39m'\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m/content/drive/My Drive/Colab Notebooks/\u001b[39m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'google.colab'"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')\n",
    "%cd /content/drive/My Drive/Colab Notebooks/\n",
    "\n",
    "data = pd.read_csv('train.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_data = data[['GrLivArea','YearBuilt','SalePrice']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 使用するデータセットの可視化\n",
    "sns.pairplot(mini_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対数変換\n",
    "log_min_data = mini_data.apply(np.log1p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 対数変換後のデータセットの可視化\n",
    "sns.pairplot(log_min_data);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数X、目的変数y\n",
    "X = log_min_data[['GrLivArea','YearBuilt']].values\n",
    "y = log_min_data['SalePrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1つのモデルでトレーニング、推定を行う\n",
    "# Cross-validation\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "# 単一モデル\n",
    "model = [LinearRegression(),\n",
    "         SVR(),\n",
    "         DecisionTreeRegressor()]\n",
    "\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=5,random_state=None, shuffle=False)\n",
    "\n",
    "# 5つのパートで検証されたメトリクスMSE\n",
    "for regr in model:\n",
    "    result = -cross_val_score(regr,X,y, cv = kf, scoring = \"neg_mean_squared_error\")\n",
    "    result_mean = np.mean(result)\n",
    "    \n",
    "    # print('CV_MSE:',result)\n",
    "    print('CV_MSE_MEAN:{:.3f}'.format(result_mean),'MODEL:',str(regr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータと検証データに分割する（ホールドアウト法）\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "train_test_split(X,y,train_size=0.8,random_state=None)\n",
    "\n",
    "print('X_train:',X_train.shape)\n",
    "print('y_train:',y_train.shape)\n",
    "print('X_valid:',X_valid.shape)\n",
    "print('y_valid:',y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ブレンディング 1\n",
    "regr1 = LinearRegression().fit(X_train,y_train)\n",
    "regr2 = SVR().fit(X_train,y_train)\n",
    "regr3 = DecisionTreeRegressor().fit(X_train,y_train)\n",
    "\n",
    "y_pred1 = regr1.predict(X_valid)\n",
    "y_pred2 = regr2.predict(X_valid)\n",
    "y_pred3 = regr3.predict(X_valid)\n",
    "\n",
    "\n",
    "# 推定値の平均値\n",
    "y_pred_blend1 = np.mean([y_pred1,y_pred2,y_pred3],axis=0)\n",
    "#print(y_pred)\n",
    "\n",
    "# 評価\n",
    "mse = mean_squared_error(y_valid,y_pred_blend1)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_valid,y_pred_blend1)\n",
    "\n",
    "print('MSE : {:.3f}'.format(mse))\n",
    "#print('RMSE: {:.3f}'.format(rmse))\n",
    "#print('R2  : {:.3f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation\n",
    "kf = KFold(n_splits=5,random_state=None, shuffle=False)\n",
    "\n",
    "params = [1,10,20]\n",
    "\n",
    "# 5つのパートで検証されたメトリクスMSE\n",
    "for rn in params:\n",
    "    # 単一モデル\n",
    "    regr = DecisionTreeRegressor(random_state=rn)\n",
    "    result = -cross_val_score(regr,X,y, cv = kf, scoring = \"neg_mean_squared_error\")\n",
    "    result_mean = np.mean(result)\n",
    "    \n",
    "    # print('CV_MSE:',result)\n",
    "    print('CV_MSE_MEAN:{:.3f}'.format(result_mean),'MODEL:',str(regr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ブレンディング 2\n",
    "regr1 = DecisionTreeRegressor(random_state=1).fit(X_train,y_train)\n",
    "regr2 = DecisionTreeRegressor(random_state=10).fit(X_train,y_train)\n",
    "regr3 = DecisionTreeRegressor(random_state=20).fit(X_train,y_train)\n",
    "\n",
    "y_pred1 = regr1.predict(X_valid)\n",
    "y_pred2 = regr2.predict(X_valid)\n",
    "y_pred3 = regr3.predict(X_valid)\n",
    "\n",
    "\n",
    "# 推定値の平均値\n",
    "y_pred_blend2 = np.mean([y_pred1,y_pred2,y_pred3],axis=0)\n",
    "#print(y_pred)\n",
    "\n",
    "# 評価\n",
    "mse = mean_squared_error(y_valid,y_pred_blend2)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_valid,y_pred_blend2)\n",
    "\n",
    "print('MSE : {:.3f}'.format(mse))\n",
    "#print('RMSE: {:.3f}'.format(rmse))\n",
    "#print('R2  : {:.3f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_mini_data = StandardScaler().fit_transform(mini_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 標準化後のデータセット可視化\n",
    "sns.pairplot(pd.DataFrame(std_mini_data));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数X、目的変数y\n",
    "X = std_mini_data[:,:-1]\n",
    "y = std_mini_data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# トレーニングデータと検証データに分割する（ホールドアウト法）\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_valid, y_train, y_valid = \\\n",
    "train_test_split(X,y,train_size=0.8,random_state=None)\n",
    "\n",
    "print('X_train:',X_train.shape)\n",
    "print('y_train:',y_train.shape)\n",
    "print('X_valid:',X_valid.shape)\n",
    "print('y_valid:',y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単一モデル\n",
    "model = [LinearRegression(),\n",
    "         SVR(),\n",
    "         DecisionTreeRegressor()]\n",
    "\n",
    "\n",
    "# Cross-validation\n",
    "kf = KFold(n_splits=5,random_state=None, shuffle=False)\n",
    "\n",
    "# 5つのパートで検証されたメトリクスMSE\n",
    "for regr in model:\n",
    "    result = -cross_val_score(regr,X,y, cv = kf, scoring = \"neg_mean_squared_error\")\n",
    "    result_mean = np.mean(result)\n",
    "    \n",
    "    # print('CV_MSE:',result)\n",
    "    print('CV_MSE_MEAN:{:.3f}'.format(result_mean),'MODEL:',str(regr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ブレンディング 2\n",
    "regr1 = LinearRegression().fit(X_train,y_train)\n",
    "regr2 = SVR().fit(X_train,y_train)\n",
    "regr3 = DecisionTreeRegressor().fit(X_train,y_train)\n",
    "\n",
    "y_pred1 = regr1.predict(X_valid)\n",
    "y_pred2 = regr2.predict(X_valid)\n",
    "y_pred3 = regr3.predict(X_valid)\n",
    "\n",
    "\n",
    "# 推定値の平均値\n",
    "y_pred_blend3 = np.mean([y_pred1,y_pred2,y_pred3],axis=0)\n",
    "#print(y_pred)\n",
    "\n",
    "# 評価\n",
    "mse = mean_squared_error(y_valid,y_pred_blend3)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_valid,y_pred_blend3)\n",
    "\n",
    "print('MSE : {:.3f}'.format(mse))\n",
    "#print('RMSE: {:.3f}'.format(rmse))\n",
    "#print('R2  : {:.3f}'.format(r2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題2:バギングのスクラッチ実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数X、目的変数y\n",
    "X = log_min_data[['GrLivArea','YearBuilt']].values\n",
    "y = log_min_data['SalePrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(X,y,train_size=0.8,random_state=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単一モデル\n",
    "model = DecisionTreeRegressor().fit(X_train,y_train)\n",
    "y_pred = model.predict(X_valid)\n",
    "\n",
    "# 評価\n",
    "mse = mean_squared_error(y_valid,y_pred)\n",
    "print('MSE : {:.3f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# バギング\n",
    "n = 20\n",
    "models = []\n",
    "\n",
    "for i in range(n):\n",
    "    X_bagging, X_, y_bagging, y_ = \\\n",
    "    train_test_split(X_train,y_train,train_size=0.2,shuffle=True)\n",
    "    \n",
    "    model = DecisionTreeRegressor()\n",
    "    model.fit(X_bagging,y_bagging)\n",
    "    models.append(model)\n",
    "\n",
    "y_pred = np.zeros(len(X_valid))\n",
    "\n",
    "for regr in models:\n",
    "    pred = regr.predict(X_valid)\n",
    "    y_pred = y_pred + pred\n",
    "    \n",
    "y_pred = y_pred/n\n",
    "\n",
    "# 評価\n",
    "mse = mean_squared_error(y_valid,y_pred)\n",
    "print('MSE : {:.3f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 問題3:スタッキングのスクラッチ実装"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Stacking():\n",
    "    \"\"\"\n",
    "    スタッキングのClass\n",
    "    Parameters\n",
    "    ----------\n",
    "    max_depth : int\n",
    "      スタッキング可能な最大学習深度\n",
    "    splits : int\n",
    "      ブレンドデータ作成時のデータ分割数（CV分割数）\n",
    "    models : dictionary\n",
    "      学習モデル {key:n_depth, values:model} を渡す\n",
    "    fit_models : list\n",
    "      保存する学習済みモデルのリスト\n",
    "    \"\"\"\n",
    "    def __init__(self, max_depth, splits, models):\n",
    "        self.max_depth = max_depth\n",
    "        self.n_splits = splits\n",
    "        self.models = models\n",
    "        self.fit_models = []\n",
    "        \n",
    "    def blending(self,X,y,m):\n",
    "        \"\"\"\n",
    "        ブレンドデータ作成機能\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形の ndarray、形状 (n_samples、n_features)\n",
    "            訓練データの特徴\n",
    "        y : 次の形の ndarray, shape (n_samples,)\n",
    "            学習データのラベル値\n",
    "        m : class\n",
    "            トレーニングモデルのインスタンス\n",
    "        \"\"\"\n",
    "        self.y_blend = np.zeros(len(X))\n",
    "        \n",
    "        kf = KFold(n_splits=self.n_splits, shuffle=False)\n",
    "        \n",
    "        # CV\n",
    "        for train_index, valid_index in kf.split(X):\n",
    "            #print('KFold',count,'/',kf.get_n_splits())\n",
    "            #print(\"TRAIN:\", train_index, \"TEST:\", test_index)\n",
    "            X_train, X_valid = X[train_index], X[valid_index]\n",
    "            y_train, y_valid = y[train_index], y[valid_index]\n",
    "            \n",
    "            y_train = y_train.ravel()\n",
    "            y_valid = y_valid.ravel()\n",
    "            \n",
    "            \n",
    "            # トレーニングデータによるトレーニングモデル作成\n",
    "            regr =  m\n",
    "            regr.fit(X_train, y_train)\n",
    "            # print(regr.predict(X_valid))\n",
    "            self.fit_models.append(regr)\n",
    "            \n",
    "            # ブレンドデータ作成\n",
    "            self.y_blend[valid_index] = regr.predict(X_valid)\n",
    "    \n",
    "    def fit_(self,X,y,depth):\n",
    "        \"\"\"\n",
    "        この深さでブレンドデータを作成する\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形の ndarray、形状 (n_samples、n_features)\n",
    "            訓練データの特徴\n",
    "        y : 次の形の ndarray, shape (n_samples,)\n",
    "            学習データのラベル値\n",
    "        depth : int\n",
    "            このステージの深さ\n",
    "        \"\"\"\n",
    "        self.depth=depth\n",
    "        \n",
    "        # 最終学習モデル\n",
    "        if self.depth == self.max_depth:\n",
    "            self.model = self.models[self.depth]\n",
    "            self.model.fit(X,y)\n",
    "            return\n",
    "        \n",
    "        # この深さのトレーニングモデルを用意する\n",
    "        models = self.models[self.depth]\n",
    "        self.y_blending = np.zeros([len(X),len(models)])\n",
    "        \n",
    "        # この深さのトレーニングモデルでブレンドデータを作る\n",
    "        # cvの空いている部分に入れている\n",
    "        for i,mdl in enumerate(models):\n",
    "            self.blending(X,y,mdl) \n",
    "            self.y_blending[:,i] = self.y_blend\n",
    "        #　次のステージのためのX(blend_y)\n",
    "        blend_y = self.y_blending\n",
    "        \n",
    "        # 再帰的\n",
    "        self.bld = Stacking(self.max_depth, self.n_splits, self.models)\n",
    "        self.bld.fit_(blend_y,y,depth+1)\n",
    "        \n",
    "    def predict_(self,X):\n",
    "        if self.depth == self.max_depth:\n",
    "            y_pred = self.model.predict(X)\n",
    "            return y_pred\n",
    "            \n",
    "        else:\n",
    "            tmp = 0\n",
    "            self.y_pred = np.zeros(len(X))\n",
    "            self.y_next = np.zeros([len(X),len(self.models[self.depth])])\n",
    "            \n",
    "            for mdl in self.fit_models:\n",
    "                tmp+=1\n",
    "                self.y_pred += mdl.predict(X)\n",
    "                \n",
    "                if tmp%self.n_splits == 0:\n",
    "                    self.y_pred = self.y_pred/self.n_splits\n",
    "                    self.y_next[:,int(tmp/self.n_splits)-1] = self.y_pred\n",
    "                    self.y_pred = np.zeros(len(X))\n",
    "                    \n",
    "            y_pred = self.bld.predict_(self.y_next)\n",
    "            \n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 説明変数X、目的変数y\n",
    "X = log_min_data[['GrLivArea','YearBuilt']].values\n",
    "y = log_min_data['SalePrice'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = \\\n",
    "    train_test_split(X,y,train_size=0.8,random_state=None)\n",
    "\n",
    "print('X_train:',X_train.shape)\n",
    "print('y_train:',y_train.shape)\n",
    "print('X_valid:',X_valid.shape)\n",
    "print('y_valid:',y_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = {0:[LinearRegression(),DecisionTreeRegressor(),RandomForestRegressor()],\n",
    "         1:[ARDRegression(),SGDRegressor(),DecisionTreeRegressor()],\n",
    "         2:[HuberRegressor(),ARDRegression(),RandomForestRegressor()],\n",
    "         3:LinearRegression()\n",
    "         }\n",
    "\n",
    "stk = Stacking(max_depth=3,splits=5,models=model)\n",
    "stk.fit_(X_train,y_train,0)\n",
    "y_pred = stk.predict_(X_valid)\n",
    "print(y_pred)\n",
    "\n",
    "# 評価\n",
    "mse = mean_squared_error(y_valid,y_pred)\n",
    "print('MSE : {:.3f}'.format(mse))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# モデルサンプル\n",
    "model =    {\"LinearRegression\": LinearRegression(),\n",
    "            \"Ridge\": Ridge(),\n",
    "            \"Lasso\": Lasso(),\n",
    "            \"ElasticNet\": ElasticNet(), \n",
    "            \"Polynomial_deg2\": Pipeline([('poly', PolynomialFeatures(degree=2)),('linear', LinearRegression())]),\n",
    "            \"Polynomial_deg3\": Pipeline([('poly', PolynomialFeatures(degree=3)),('linear', LinearRegression())]),\n",
    "            \"Polynomial_deg4\": Pipeline([('poly', PolynomialFeatures(degree=4)),('linear', LinearRegression())]),\n",
    "            \"Polynomial_deg5\": Pipeline([('poly', PolynomialFeatures(degree=5)),('linear', LinearRegression())]),\n",
    "            \"KNeighborsRegressor\": KNeighborsRegressor(n_neighbors=3),\n",
    "            \"DecisionTreeRegressor\": DecisionTreeRegressor(),\n",
    "            \"RandomForestRegressor\": RandomForestRegressor(),\n",
    "            \"SVR\": SVR(kernel='rbf', C=1e3, gamma=0.1, epsilon=0.1),\n",
    "            \"GaussianProcessRegressor\": GaussianProcessRegressor(),\n",
    "            \"SGDRegressor\": SGDRegressor(),\n",
    "            \"MLPRegressor\": MLPRegressor(hidden_layer_sizes=(10,10), max_iter=100, early_stopping=True, n_iter_no_change=5),\n",
    "            \"ExtraTreesRegressor\": ExtraTreesRegressor(n_estimators=100), \n",
    "            \"PLSRegression\": PLSRegression(n_components=10),\n",
    "            \"PassiveAggressiveRegressor\": PassiveAggressiveRegressor(max_iter=100, tol=1e-3),\n",
    "            \"TheilSenRegressor\": TheilSenRegressor(random_state=0),\n",
    "            \"RANSACRegressor\": RANSACRegressor(random_state=0),\n",
    "            \"HistGradientBoostingRegressor\": HistGradientBoostingRegressor(),\n",
    "            \"AdaBoostRegressor\": AdaBoostRegressor(random_state=0, n_estimators=100),\n",
    "            \"BaggingRegressor\": BaggingRegressor(base_estimator=SVR(), n_estimators=10),\n",
    "            \"GradientBoostingRegressor\": GradientBoostingRegressor(random_state=0),\n",
    "            \"VotingRegressor\": VotingRegressor([('lr', LinearRegression()), ('rf', RandomForestRegressor(n_estimators=10))]),\n",
    "            \"StackingRegressor\": StackingRegressor(estimators=[('lr', RidgeCV()), ('svr', LinearSVR())], final_estimator=RandomForestRegressor(n_estimators=10)),\n",
    "            \"ARDRegression\": ARDRegression(),\n",
    "            \"HuberRegressor\": HuberRegressor(),\n",
    "            }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bde1ea82a499da0f3bee45254b930e19212c5f0c991811db65179495d8206895"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
